{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## This is the Network Described in paper\n","I understand we tweaked the input so it may need to be changed"],"metadata":{"id":"2hV66RQ2NYtz"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDuXC3Rwc76r","executionInfo":{"status":"ok","timestamp":1690043704533,"user_tz":-60,"elapsed":27772,"user":{"displayName":"Chanyu Yang (Miya)","userId":"17795092151950248765"}},"outputId":"bdfe45c5-f888-416a-fc1d-6991b9b77d4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/GT/CS7643DL/Group_project/share_folder/CS7643_group_project/data/data_for_DL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8imoU-UzdOsz","executionInfo":{"status":"ok","timestamp":1690043830894,"user_tz":-60,"elapsed":230,"user":{"displayName":"Chanyu Yang (Miya)","userId":"17795092151950248765"}},"outputId":"a21fc3fe-6857-426c-c5ff-735ee25af52c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GT/CS7643DL/Group_project/share_folder/CS7643_group_project/data/data_for_DL\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv1d(28, 64, kernel_size=2, padding=1)\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.conv2 = nn.Conv1d(64, 128, kernel_size=2, padding=1)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.fc1 = nn.Linear(128 * 2104, 512)\n","        self.bn3 = nn.BatchNorm1d(512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.bn4 = nn.BatchNorm1d(256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.bn5 = nn.BatchNorm1d(128)\n","        self.fc4 = nn.Linear(128, 581061)\n","\n","        self.dropout = nn.Dropout(p=0.2)  # Set dropout rate to 0.2\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = F.relu(self.bn3(self.fc1(x)))\n","        x = self.dropout(x)  # Apply dropout with a rate of 0.2\n","        x = F.relu(self.bn4(self.fc2(x)))\n","        x = self.dropout(x)  # Apply dropout with a rate of 0.2\n","        x = F.relu(self.bn5(self.fc3(x)))\n","        x = self.fc4(x)\n","        return x\n","\n","# Create an instance of the ConvNet model\n","model = ConvNet()\n","\n","# Create random input and target tensors with a batch size of 32\n","batch_size = 32\n","input_features = torch.randn(batch_size, 28, 2104)\n","target = torch.randn(batch_size, 581061)\n","\n","# Define the optimizer (Adam)\n","optimizer = optim.Adam(model.parameters())\n","\n","# Forward pass\n","output = model(input_features)\n","\n","# Print the output shape\n","print(\"Output shape:\", output.shape)\n"],"metadata":{"id":"QQlB2lQeNbn9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# KAIs UPDATED MODEL:\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv1d(10, 31, kernel_size=2, padding=0)  # Adjust input channels to 10\n","        self.bn1 = nn.BatchNorm1d(31)\n","        self.conv2 = nn.Conv1d(31, 32, kernel_size=2, padding=1)\n","        self.bn2 = nn.BatchNorm1d(32)\n","        # Adjust the input size after flattening\n","        self.fc1 = nn.Linear(32, 512)\n","\n","        self.bn3 = nn.BatchNorm1d(512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.bn4 = nn.BatchNorm1d(256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.bn5 = nn.BatchNorm1d(128)\n","        self.fc4 = nn.Linear(128, 16836)\n","\n","        self.dropout = nn.Dropout(p=0.2)  # Set dropout rate to 0.2\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = F.relu(self.bn3(self.fc1(x)))\n","        x = self.dropout(x)  # Apply dropout with a rate of 0.2\n","        x = F.relu(self.bn4(self.fc2(x)))\n","        x = self.dropout(x)  # Apply dropout with a rate of 0.2\n","        x = F.relu(self.bn5(self.fc3(x)))\n","        x = self.fc4(x)\n","        return x\n","\n","# Create an instance of the ConvNet model\n","model = ConvNet()\n","\n"],"metadata":{"id":"D5Crwcb3ABRZ"},"execution_count":null,"outputs":[]}]}